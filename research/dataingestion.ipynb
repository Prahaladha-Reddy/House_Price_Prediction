{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "  root_dir:Path\n",
    "  source_url:str\n",
    "  local_data_file:Path\n",
    "  unzip_dir:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformConfig:\n",
    "  root_dir:Path\n",
    "  local_data_file: Path\n",
    "  train_path: Path\n",
    "  test_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCleaningConfing:\n",
    "  root_dir: Path\n",
    "  train_path: Path\n",
    "  test_path: Path\n",
    "  cleaned_train_path: Path\n",
    "  cleaned_test_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainingConfig:\n",
    "  root_dir:Path\n",
    "  cleaned_train_path: Path\n",
    "  cleaned_test_path: Path\n",
    "  model:Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelValidationConfig:\n",
    "    root_dir: Path\n",
    "    cleaned_test_path:Path\n",
    "    model: Path\n",
    "    scores: Path\n",
    "    ResidualDistribution: Path\n",
    "    ResidualsVSPredictions: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *\n",
    "from src.datascience.utils.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/bored/Music/My_own/research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bored\\\\Music\\\\My_own\\\\research'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filepath=CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\config\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(config_filepath.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "  def __init__(self,config_filepath=CONFIG_FILE_PATH,\n",
    "               schema_filepath=SCHEMA_FILE_PATH,\n",
    "               params_filepath=PARAMS_FILE_PATH):\n",
    "    print(schema_filepath)\n",
    "    self.config=read_yaml(config_filepath)\n",
    "    self.schema=read_yaml(schema_filepath)\n",
    "    self.params=read_yaml(params_filepath)\n",
    "    crate_directories([self.config.artifacts_root])\n",
    "  def get_data_ingestion_config(self)->DataIngestionConfig:\n",
    "    config=self.config.data_ingestion\n",
    "    crate_directories([config.root_dir])\n",
    "    data_ingestion_config=DataIngestionConfig(\n",
    "      root_dir=config.root_dir,\n",
    "      source_url=config.source_url,\n",
    "      local_data_file=config.local_data_file,\n",
    "      unzip_dir=config.unzip_dir\n",
    "    )\n",
    "    return data_ingestion_config\n",
    "  def get_data_transform(self)->DataTransformConfig:\n",
    "    config=self.config.data_transform\n",
    "    crate_directories([config.root_dir])\n",
    "    data_trainsform_config=DataTransformConfig(\n",
    "    root_dir=config.root_dir,\n",
    "    local_data_file=config.local_data_file,\n",
    "    train_path=config.train_path,\n",
    "    test_path= config.test_path\n",
    "    )\n",
    "    return data_trainsform_config\n",
    "  def get_data_clean(self)->DataCleaningConfing:\n",
    "    config=self.config.data_cleaning\n",
    "    crate_directories([config.root_dir])\n",
    "    data_clean_config=DataCleaningConfing(\n",
    "       root_dir= config.root_dir ,\n",
    "        train_path= config.train_path ,\n",
    "        test_path = config.test_path ,\n",
    "        cleaned_train_path= config.cleaned_train_path ,\n",
    "        cleaned_test_path= config.cleaned_test_path ,\n",
    "    )\n",
    "    return data_clean_config\n",
    "  def get_model_training(self)->ModelTrainingConfig:\n",
    "    config=self.config.model_training\n",
    "    crate_directories([config.root_dir])\n",
    "    Model_Training_config=ModelTrainingConfig(\n",
    "      root_dir=config.root_dir,\n",
    "      cleaned_train_path=config.cleaned_train_path,\n",
    "      cleaned_test_path=config.cleaned_test_path,\n",
    "      model=config.model\n",
    "    )\n",
    "    return Model_Training_config\n",
    "  def get_model_evaluation(self)->ModelValidationConfig:\n",
    "    print('Hitting the get model_evaluation')\n",
    "    config=self.config.model_validation\n",
    "    print('got model_validation')\n",
    "    crate_directories([config.root_dir])\n",
    "    print('creatig')\n",
    "    Model_Validation_config=ModelValidationConfig(\n",
    "      root_dir=config.root_dir,\n",
    "      scores=config.scores,\n",
    "      cleaned_test_path=config.cleaned_test_path,\n",
    "      model=config.model,\n",
    "      ResidualDistribution=config.ResidualDistribution,\n",
    "      ResidualsVSPredictions=config.ResidualsVSPredictions\n",
    "      \n",
    "    )\n",
    "    return Model_Validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from src.datascience.basicConfig import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\bored\\\\Music\\\\MY_OWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "  def __init__(self,config:DataIngestionConfig):\n",
    "    self.config=config\n",
    "  def download_file(self):\n",
    "    if not os.path.exists(self.config.local_data_file):\n",
    "      filename,header=request.urlretrieve(url=self.config.source_url,\n",
    "                                          filename=self.config.local_data_file)\n",
    "      logger.info(f'{filename} downloaded! with following info\\n{header}')\n",
    "\n",
    "    else:\n",
    "      logger.info('File already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "  def __init__(self,config:DataTransformConfig):\n",
    "    self.config=config\n",
    "  def extract_split(self):\n",
    "    self.path=self.config.local_data_file\n",
    "    data=pd.read_csv(self.path)\n",
    "    self.train,self.test=train_test_split(data,train_size=0.8,random_state=42)\n",
    "    save_file(self.train,self.config.train_path)\n",
    "    save_file(self.test,self.config.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "  def __init__(self,config:DataCleaningConfing):\n",
    "    self.config=config\n",
    "  def clean(self):\n",
    "    self.test_data=pd.read_csv(self.config.test_path)\n",
    "    self.train_data=pd.read_csv(self.config.test_path)\n",
    "    self.test_data.reset_index(drop=True,inplace=True)\n",
    "    self.test_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    self.train_data.reset_index(drop=True,inplace=True)\n",
    "    self.train_data.drop(columns=['Unnamed: 0'], inplace=True)    \n",
    "    save_file(self.test_data,self.config.cleaned_test_path)\n",
    "    save_file(self.train_data,self.config.cleaned_train_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "  def __init__(self,config:ModelTrainingConfig):\n",
    "    self.config=config\n",
    "  def data_preparation(self):\n",
    "    self.train_data=pd.read_csv(self.config.cleaned_train_path)\n",
    "    self.test_data=pd.read_csv(self.config.cleaned_test_path)\n",
    "    self.X_train=self.train_data.drop(columns=['price'])\n",
    "    self.y_train=self.train_data['price']\n",
    "    self.x_test=self.test_data.drop(columns=['price'])\n",
    "    self.y_test=self.test_data['price']\n",
    "    self.y_train_log=np.log1p(self.y_train)\n",
    "    self.y_test_log=np.log1p(self.y_test)\n",
    "  def model_training(self):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', XGBRegressor())\n",
    "    ])\n",
    "    param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200], \n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2], \n",
    "    'regressor__max_depth': [3, 5, 7], \n",
    "    'regressor__subsample': [0.6, 0.8, 1.0], \n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0], \n",
    "    'regressor__reg_alpha': [0, 0.1, 1],\n",
    "    'regressor__reg_lambda': [1, 5, 10],\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20, \n",
    "    cv=5,  \n",
    "    scoring='r2',  \n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    "    )\n",
    "    random_search.fit(self.X_train, self.y_train_log)\n",
    "    \n",
    "    with open(self.config.model, 'wb') as file:\n",
    "      pickle.dump(random_search.best_estimator_, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelValidation:\n",
    "  def __init__(self,config:ModelValidationConfig):\n",
    "    self.config=config\n",
    "    \n",
    "  def model_load(self):\n",
    "    with open(self.config.model, 'rb') as file:\n",
    "      self.loaded_model = pickle.load(file)\n",
    "  def predict(self):\n",
    "    data=pd.read_csv(self.config.cleaned_test_path)\n",
    "    self.x_test=data.drop(columns=['price'])\n",
    "    self.y_test=data['price']\n",
    "    self.y_pred_log= self.loaded_model.predict(self.x_test)\n",
    "    self.y_pred=np.expm1(self.y_pred_log)\n",
    "  def scores(self):\n",
    "    mae = mean_absolute_error(self.y_test, self.y_pred)\n",
    "    mse = mean_squared_error(self.y_test, self.y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(self.y_test, self.y_pred)\n",
    "    mape = np.mean(np.abs((self.y_test - self.y_pred) / self.y_test)) * 100\n",
    "    smape = np.mean(2 * np.abs(self.y_test - self.y_pred) / (np.abs(self.y_test) + np.abs(self.y_pred))) * 100\n",
    "    median_ae = median_absolute_error(self.y_test, self.y_pred)\n",
    "    explained_variance = explained_variance_score(self.y_test, self.y_pred)\n",
    "    max_error = np.max(np.abs(self.y_test - self.y_pred))\n",
    "    n = len(self.y_test)\n",
    "    k = self.x_test.shape[1]\n",
    "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "    quantiles = np.quantile(self.y_test, [0.25, 0.5, 0.75])\n",
    "    for q in quantiles:\n",
    "        subset = self.y_test[self.y_test <= q]\n",
    "        r2_subset = r2_score(subset, self.y_pred[self.y_test <= q])\n",
    "    msle = mean_squared_log_error(self.y_test, self.y_pred)\n",
    "    results = {\n",
    "    \"MAE\": mae,\n",
    "    \"MSE\": mse,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Adjusted R²\": adjusted_r2,\n",
    "    \"MAPE\": mape,\n",
    "    \"SMAPE\": smape,\n",
    "    \"Median AE\": median_ae,\n",
    "    \"Explained Variance\": explained_variance,\n",
    "    \"Max Error\": max_error,\n",
    "    \"MSLE\": msle\n",
    "      }\n",
    "    self.results = pd.DataFrame(list(results.items()), columns=[\"Metric\", \"Value\"])\n",
    "    save_file(self.results,self.config.scores)\n",
    "  \n",
    "    print('scores is successful')\n",
    "    \n",
    "  def plots(self):\n",
    "    residuals = self.y_test - self.y_pred\n",
    "    # Residual Distribution Plot\n",
    "    plt.figure()\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.title(\"Residual Distribution\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid()\n",
    "    plt.savefig(self.config.ResidualDistribution, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Residuals vs Predictions Plot\n",
    "    plt.figure()\n",
    "    plt.scatter(self.y_pred, residuals, alpha=0.6)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(\"Residuals vs. Predictions\")\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.grid()\n",
    "    plt.savefig(self.config.ResidualsVSPredictions, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\schema.yaml\n",
      "[2024-12-03 18:49:28,736 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n",
      "[2024-12-03 18:49:28,739 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\schema.yaml is loaded safely]\n",
      "[2024-12-03 18:49:28,742 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\params.yaml is loaded safely]\n",
      "[2024-12-03 18:49:28,743 : INFO : common : Created directory artifacts]\n",
      "[2024-12-03 18:49:28,745 : INFO : common : Created directory artifacts/data_ingestion]\n",
      "[2024-12-03 18:49:29,877 : INFO : 1387786406 : artifacts/data_ingestion/data.csv downloaded! with following info\n",
      "Connection: close\n",
      "Content-Length: 65642\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: text/plain; charset=utf-8\n",
      "ETag: \"7a3b21963b623a3d9ec3c3d18549b285a9610e60ac27f90a49b1c0138b1ee0f0\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: 63CC:277C77:15193C:19F72A:674F0560\n",
      "Accept-Ranges: bytes\n",
      "Date: Tue, 03 Dec 2024 13:19:29 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-maa10249-MAA\n",
      "X-Cache: MISS\n",
      "X-Cache-Hits: 0\n",
      "X-Timer: S1733231969.248555,VS0,VE372\n",
      "Vary: Authorization,Accept-Encoding,Origin\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: 2ec382c08a27fb568c567165d5567052860e2a19\n",
      "Expires: Tue, 03 Dec 2024 13:24:29 GMT\n",
      "Source-Age: 0\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  config=ConfigurationManager()\n",
    "  data_ingestion_config=config.get_data_ingestion_config()\n",
    "  data_ingestion=DataIngestion(config=data_ingestion_config)\n",
    "  data_ingestion.download_file()\n",
    "except Exception as e:\n",
    "  raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\schema.yaml\n",
      "[2024-12-03 18:49:29,901 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,907 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\schema.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,911 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\params.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,913 : INFO : common : Created directory artifacts]\n",
      "[2024-12-03 18:49:29,915 : INFO : common : Created directory artifacts/data_transform]\n",
      "[2024-12-03 18:49:29,943 : INFO : common : File saved successfully at artifacts/data_transform/train.csv]\n",
      "[2024-12-03 18:49:29,950 : INFO : common : File saved successfully at artifacts/data_transform/test.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  config=ConfigurationManager()\n",
    "  data_transform_config=config.get_data_transform()\n",
    "  data_transform=DataTransform(config=data_transform_config)\n",
    "  data_transform.extract_split()\n",
    "  \n",
    "except Exception as e:\n",
    "  raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\schema.yaml\n",
      "[2024-12-03 18:49:29,977 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,978 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\schema.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,982 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\params.yaml is loaded safely]\n",
      "[2024-12-03 18:49:29,985 : INFO : common : Created directory artifacts]\n",
      "[2024-12-03 18:49:29,986 : INFO : common : Created directory artifacts/data_clean]\n",
      "[2024-12-03 18:49:30,005 : INFO : common : File saved successfully at artifacts/data_clean/test.csv]\n",
      "[2024-12-03 18:49:30,008 : INFO : common : File saved successfully at artifacts/data_clean/train.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  config=ConfigurationManager()\n",
    "  data_transform_config=config.get_data_clean()\n",
    "  data_transform=DataCleaning(config=data_transform_config)\n",
    "  data_transform.clean()\n",
    "except Exception as e:\n",
    "  raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\schema.yaml\n",
      "[2024-12-03 18:49:30,044 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n",
      "[2024-12-03 18:49:30,051 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\schema.yaml is loaded safely]\n",
      "[2024-12-03 18:49:30,072 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\params.yaml is loaded safely]\n",
      "[2024-12-03 18:49:30,084 : INFO : common : Created directory artifacts]\n",
      "[2024-12-03 18:49:30,088 : INFO : common : Created directory artifacts/model_train]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "  config=ConfigurationManager()\n",
    "  model_training_config=config.get_model_training()\n",
    "  model_trainingg=ModelTraining(config=model_training_config)\n",
    "  model_trainingg.data_preparation()\n",
    "  model_trainingg.model_training()\n",
    "except Exception as e:\n",
    "  raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bored\\Music\\My_own\\schema.yaml\n",
      "[2024-12-03 18:52:42,275 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n",
      "[2024-12-03 18:52:42,278 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\schema.yaml is loaded safely]\n",
      "[2024-12-03 18:52:42,280 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\params.yaml is loaded safely]\n",
      "[2024-12-03 18:52:42,284 : INFO : common : Created directory artifacts]\n",
      "Hitting the get model_evaluation\n",
      "got model_validation\n",
      "[2024-12-03 18:52:42,288 : INFO : common : Created directory artifacts/model_validation]\n",
      "creatig\n",
      "success1\n",
      "success2\n",
      "[2024-12-03 18:52:42,316 : INFO : common : File saved successfully at artifacts/model_validation/scores.csv]\n",
      "scores is successful\n",
      "success3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  config=ConfigurationManager()\n",
    "  model_evaluation_config=config.get_model_evaluation()  # Correct config retrieval\n",
    "  model_evaluationn=ModelValidation(config=model_evaluation_config) \n",
    "  model_evaluationn.model_load()\n",
    "  print('success1')\n",
    "  model_evaluationn.predict()\n",
    "  print('success2')\n",
    "  model_evaluationn.scores()\n",
    "  print('success3')\n",
    "  model_evaluationn.plots()\n",
    "except Exception as e:\n",
    "  raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-03 18:49:35,558 : INFO : common : YAML file C:\\Users\\bored\\Music\\My_own\\config\\config.yaml is loaded safely]\n"
     ]
    }
   ],
   "source": [
    "config=read_yaml(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=config.model_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/model_train/model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(m.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_validation: {'root_dir': 'artifacts/model_validation', 'cleaned_test_path': 'artifacts/data_clean/test.csv', 'model': 'artifacts/model_train/model.pkl', 'ResidualDistribution': 'artifacts/model_validation/ResidualDistribution.png', 'ResidualsVSPredictions': 'artifacts/model_validation/ResidualsVSPredictions.png', 'FeatureImportance': 'artifacts/model_validation/FeatureImportance.png', 'LearningCurve': 'artifacts/model_validation/LearningCurve.png', 'scores': 'artifacts/model_validation/scores.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(\"model_validation:\", config.get(\"model_validation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
